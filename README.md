# LangGraph Agent API

A powerful AI agent built with LangGraph and FastAPI that provides calculator, web search, database query, and image analysis capabilities with **real-time streaming responses**.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- OpenAI API key

### Installation

1. **Clone and install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set up environment variables:**
   Create a `.env` file:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   ```

### Running the Server

**Recommended:**
```bash
python run_server.py
```

**Alternative methods:**
```bash
# Using Granian directly
python -m granian --interface asgi app.main:app --host 0.0.0.0 --port 8000 --reload

# CLI version
python main.py
```

### Testing

```bash
python test_server.py    # Test basic endpoints
python test_tools.py     # Test agent capabilities  
python test_streaming.py # Test streaming functionality
```

**Interactive API docs:** `http://localhost:8000/docs`

## ğŸ› ï¸ Agent Capabilities

| Tool | Description | Example |
|------|-------------|---------|
| **Calculator** | Mathematical calculations | `"Calculate 15 * 8 + sqrt(144)"` â†’ `132.0` |
| **Web Search** | DuckDuckGo search | `"Search for Python tutorials"` â†’ Top results with links |
| **Database** | User information lookup | `"Fetch user2 from database"` â†’ User details |
| **Image Analysis** | Analyze images from URLs/files | `"Analyze this image: https://..."` |

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | Welcome message |
| `GET` | `/health` | Health check |
| `GET` | `/agent/info` | Agent information |
| `GET` | `/agent/capabilities` | Available tools |
| `POST` | `/chat` | Chat with agent (regular) |
| `POST` | `/chat/stream` | **Chat with streaming responses** |

### Regular Chat
```bash
curl -X POST "http://localhost:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{"message": "Calculate 25 * 4 + sqrt(81)"}'
```

### Streaming Chat
```bash
curl -X POST "http://localhost:8000/chat/stream" \
     -H "Content-Type: application/json" \
     -d '{"message": "Calculate 25 * 4", "stream": true}' \
     --no-buffer
```

## ğŸŒŠ Streaming Features

### Real-time Token Streaming
- **Token-by-token responses** as they're generated
- **Tool execution status** updates in real-time
- **Better user experience** with immediate feedback

### Streaming Events
| Event | Description |
|-------|-------------|
| `token` | Individual response tokens |
| `tool_start` | Tool execution beginning |
| `tool_end` | Tool execution completed |
| `error` | Error handling |
| `done` | Response completion |

### Web Client
Open `streaming_client.html` in your browser for a beautiful real-time chat interface.

### Python Streaming Client
```python
import requests
import json

def stream_chat(message):
    response = requests.post(
        'http://localhost:8000/chat/stream',
        json={"message": message, "stream": True},
        stream=True
    )
    
    for line in response.iter_lines():
        if line and line.startswith(b'data: '):
            event = json.loads(line[6:])
            if event['event'] == 'token':
                print(event['data'], end='', flush=True)

# Usage
stream_chat("What can you do?")
```

## ğŸ—ï¸ Project Structure

```
langgraph-agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # FastAPI application with streaming
â”‚   â”œâ”€â”€ agent.py         # LangGraph agent implementation
â”‚   â””â”€â”€ models.py        # Pydantic models
â”œâ”€â”€ test_server.py       # API endpoint tests
â”œâ”€â”€ test_tools.py        # Agent capability tests
â”œâ”€â”€ test_streaming.py    # Streaming functionality tests
â”œâ”€â”€ streaming_client.html # Web client for testing
â”œâ”€â”€ run_server.py        # Server runner script
â”œâ”€â”€ main.py              # CLI version
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md           # This file
```

## ğŸ”§ Development

**Start with auto-reload:**
```bash
python -m granian --interface asgi app.main:app --host 0.0.0.0 --port 8000 --reload
```

**Environment variables:**
```env
# Required
OPENAI_API_KEY=your_key_here

# Optional
HOST=0.0.0.0
PORT=8000
RELOAD=true
MODEL_NAME=gpt-4o-mini
TEMPERATURE=0
```

## âœ… Status

All components working correctly:
- âœ… Server starts successfully
- âœ… API endpoints respond
- âœ… **Streaming responses work**
- âœ… Calculator tool works
- âœ… Database tool works  
- âœ… Search tool works
- âœ… Image analysis available
- âœ… Error handling implemented

## ğŸ§ª Testing Streaming

### Interactive Mode
```bash
python test_streaming.py
```

### Batch Testing
```bash
python test_streaming.py batch
```

### Single Message
```bash
python test_streaming.py single "Calculate 2+2"
```

## ğŸ› Troubleshooting

**Server won't start:**
- Check if port 8000 is available
- Verify OpenAI API key is set
- Install missing dependencies: `pip install -r requirements.txt`

**Streaming not working:**
- Ensure you're using the `/chat/stream` endpoint
- Check that `stream: true` is in the request body
- Verify the client supports Server-Sent Events

**Tools not working:**
- Ensure OpenAI API key is valid
- Check internet connection for search tool
